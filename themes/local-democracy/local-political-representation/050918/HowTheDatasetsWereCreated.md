### Build a Database of Councillors and Deprivation

You will need:
-	url and lad.xlsx 
-	Web scraping code.py
-	Calculate the overall repr and lad.py
-	Merge councillors in England and ONS data.py
-	Add IMD scores.py

Read me:
The ‘url and lad’ spreadsheet contains a list of the council websites and their corresponding local authority district. This was obtained from the old dataset, but some URLs were changed to find a common html format for all websites. I found that websites that listed councillors by wards in a table or a list, could be accounted for in a single webscraper. Some examples of the format of websites that could be scraped:
http://democracy.allerdale.gov.uk/mgMemberIndex.aspx?VW=TABLE&PIC=1&FN=WARD

https://democracy.blackpool.gov.uk/mgMemberIndex.aspx?FN=WARD&VW=LIST&PIC=0

The ‘Web scraping code’ then goes through this list of URLs. It scrapes the wards and the political parties of the councillors in that ward. It creates two spreadsheets, one with the web scraped data, and another with a list of websites that could not be scraped, with any errors that occurred in web scraping. There are three ‘errors’ that have to be accounted for in the webscraped data. Firstly, there is one website that lists the councillor parties along with the date that they were elected, so the data reads ‘Elected June 2015 (Conservative)’. The political party text cannot be separated in the html without several lines of unnecessary code for just one website. Therefore, the dates that the councillors were elected needed to be deleted from the councillor columns for the Tendring website: https://tdcdemocracy.tendringdc.gov.uk/mgMemberIndex.aspx?VW=TABLE&PIC=1&FN=PARTY

Secondly, if the political party of a councillor is left blank on the website, it either means that there is a vacant councillor spot, or a councillor does not give their political affiliation. In this case, the code writes ‘Not specified’ in the councillor column, and this in turn needed to be checked manually. If the councillor spot is vacant, then that column was deleted (perhaps we could have noted these to look out for new elections?). However, if there is a councillor but they don’t give their party, sometimes their party can be found elsewhere on the website, or they are genuinely not part of a political party and remain as ‘Not specified’. Therefore, City of London, which has more than three councillors per ward, all with no political affiliation, has several ‘Not specified’ columns. Since these wards aren’t included by the ONS anyway, this can be ignored.

Thirdly, if the mayor is listed on the website with the councillors, the code also scrapes the mayor information. This is not particularly an error and can stay on the spreadsheet, as it won’t be transferred onto the final electoral ward data. However, it is a slight annoyance because often the mayor information is formatted differently to the councillor information on the website. The mayor’s political affiliation is usually written in the ward section, and the mayor’s title in the political party section, and so this is how it is written onto the spreadsheet. But again, this can be ignored.

I then got the data manually for the remaining websites, naming the separate spreadsheet ‘Manual wards’.  This spreadsheet is in the same format as the webscraped data – wards in column 1; councillors in columns 2,3,4; overall representation in 5; LAD in 6; URL in column 7. However, I left the representation and LAD columns blank as I wrote a script that would fill these in for me. The manual wards spreadsheet must be in this format for the subsequent code to work. (I have attached the manual wards spreadsheet to the email, so that when the database needs updating, this spreadsheet can be reused and just amended based on boundary and councillor changes).
 
The script ‘Calculate the overall repr and lad’ uses this spreadsheet ‘Manual wards’ and ‘url and lad’ to calculate the overall representation and fill in the local authority district. The code works by matching the URLs in the manual wards spreadsheet to the original set of URLs in ‘url and lad’. Therefore, if there were any mistakes in copying and pasting the URLs in ‘Manual wards’, the code won’t work and will print this error. The code saves the new data as ‘Manual wards with repr and lad’. This data can then be added to the webscraped data to make a complete set of councillors in England named ‘Final councillors list’. 

In calculating the overall representation, some assumptions had to be made. The overall representations are Labour, Conservative, Liberal Democrat, Green, UKIP, NOC (no overall control) and Other. In calculating these, it can be assumed that councillors that are a part of two political parties, vote with the larger party. For example: ‘Labour & Co-op’ is considered overall Labour; ‘Broadland Conservative Group’ is Conservative; ‘Tendring First/Liberal Democrat’ is considered overall Liberal Democrat. I think it’s safe to assume this, as if a councillor gives two parties, often the smaller separate party is not registered with the electoral commission. Also, even if they are called ‘Broadland Conservative Group’ on their website, they are in fact the Conservative Party but choose to add their ward or district name like ‘Broadland’ for some reason. The ‘Other’ refers to everything else, such as independent groups or residents’ associations. 

The ONS (finally) released the conversion between 2011 LSOAs and 2018 electoral wards. The ‘Merge councillors’ script uses the ONS database of LSOAs and the ‘Final councillors list’ to transfer all the councillor information onto the ONS database creating a new file ‘Total data’. The code works by matching up the LAD strings, and then matching the ward strings within that LAD. If there were any wards that couldn’t be matched up, the script prints these out and they remain on the new database, but with their councillor information missing. This is because some wards are spelt wrong/differently on their website to the ONS database, and therefore could not be matched up in the code e.g. ‘Hatfield Heath’ is accidently spelt ‘Hatfield Health’ on its website. There should be about 25 of these wards, and their information can be transferred manually.

The code also exposes whether the LAD names on the ‘Final councillors list’ are correctly matched up with their respective wards, since the code cannot match up the wards for each LAD if their LAD has been listed incorrectly. In this case, it is possible to go back to the ‘Final councillors list’ and check the information for wards that did not transfer onto the new database. 

After filling in the remaining information manually, the IMD scores were added on. This was done by ordering the new and old database by alphabetical LSOA code. Since IMD scores are assigned to each LSOA, the IMD scores could then be added to the new database line by line, using ‘Add IMD scores.py’. This is a much quicker way of writing the deprivation scores to the file, rather than matching up the LSOA code strings, as there are over 30,000 LSOAs. Therefore, to add the IMD scores, the new database ‘Total Data’ and the IMD data must both be ordered by alphabetical LSOA code before running the script. This completes the dataset, saving it as ‘Deprivation in England’.
